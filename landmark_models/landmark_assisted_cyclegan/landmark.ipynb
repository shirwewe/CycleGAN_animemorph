{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw\n",
    "from CFA import CFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param\n",
    "num_landmark = 24\n",
    "img_width = 128\n",
    "checkpoint_name = 'checkpoint_landmark_191116.pth'\n",
    "input_img_name = '/home/jempio/documents/aps360-project/data/dataSetB_10k/36253_2011.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Assuming CFA and other necessary imports are already available\n",
    "# detector\n",
    "face_detector = cv2.CascadeClassifier('lbpcascade_animeface.xml')\n",
    "landmark_detector = CFA(output_channel_num=num_landmark + 1, checkpoint_name=checkpoint_name).cuda()\n",
    "\n",
    "# transform\n",
    "normalize = transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "train_transform = [transforms.ToTensor(), normalize]\n",
    "train_transform = transforms.Compose(train_transform)\n",
    "\n",
    "# input image & detect face\n",
    "img = cv2.imread(input_img_name)\n",
    "if img is None:\n",
    "    raise FileNotFoundError(f\"Unable to load image at {input_img_name}\")\n",
    "faces = face_detector.detectMultiScale(img)\n",
    "\n",
    "# Create a black image with the same size\n",
    "black_img = np.zeros_like(img)\n",
    "black_img = Image.fromarray(black_img)  # Initialize with black background\n",
    "draw = ImageDraw.Draw(black_img)\n",
    "\n",
    "# Convert the original image to PIL Image for cropping\n",
    "img_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "for x_, y_, w_, h_ in faces:\n",
    "\n",
    "    # adjust face size\n",
    "    x = max(x_ - w_ / 8, 0)\n",
    "    rx = min(x_ + w_ * 9 / 8, black_img.width)\n",
    "    y = max(y_ - h_ / 4, 0)\n",
    "    by = y_ + h_\n",
    "    w = rx - x\n",
    "    h = by - y\n",
    "\n",
    "    # draw result of face detection\n",
    "    draw.rectangle((x, y, x + w, y + h), outline=(255, 255, 255), width=3)\n",
    "\n",
    "    # transform image\n",
    "    img_tmp = img_pil.crop((x, y, x+w, y+h))\n",
    "    img_tmp = img_tmp.resize((img_width, img_width), Image.BICUBIC)\n",
    "    img_tmp = train_transform(img_tmp)\n",
    "    img_tmp = img_tmp.unsqueeze(0).cuda()\n",
    "\n",
    "    # estimate heatmap\n",
    "    heatmaps = landmark_detector(img_tmp)\n",
    "    heatmaps = heatmaps[-1].cpu().detach().numpy()[0]\n",
    "\n",
    "    landmarks = []\n",
    "\n",
    "    # calculate landmark position\n",
    "    for i in range(num_landmark):\n",
    "        heatmaps_tmp = cv2.resize(heatmaps[i], (img_width, img_width), interpolation=cv2.INTER_CUBIC)\n",
    "        landmark = np.unravel_index(np.argmax(heatmaps_tmp), heatmaps_tmp.shape)\n",
    "        landmark_y = landmark[0] * h / img_width\n",
    "        landmark_x = landmark[1] * w / img_width\n",
    "\n",
    "        landmarks.append((x + landmark_x, y + landmark_y))\n",
    "\n",
    "        # draw landmarks\n",
    "        draw.ellipse((x + landmark_x - 2, y + landmark_y - 2, x + landmark_x + 2, y + landmark_y + 2), fill=(255, 255, 255))\n",
    "\n",
    "    # draw boxes around eyes, nose, and mouth\n",
    "    # Adjust indices based on specific model\n",
    "    eyebrow_left_indices = [3, 4, 5]\n",
    "    eyebrow_right_indices = [6, 7, 8]\n",
    "    eye_left_indices = [0, 10, 11, 12, 13, 14]\n",
    "    eye_right_indices = [2, 15, 16, 17, 18, 19]\n",
    "    nose_indices = [9]\n",
    "    mouth_indices = [1, 20, 22, 23]\n",
    "\n",
    "    def get_bounding_box(points):\n",
    "        x_coords = [p[0] for p in points]\n",
    "        y_coords = [p[1] for p in points]\n",
    "        return (min(x_coords), min(y_coords), max(x_coords), max(y_coords))\n",
    "\n",
    "    if all(i < num_landmark for i in eyebrow_left_indices):\n",
    "        eyebrow_left_points = [landmarks[i] for i in eyebrow_left_indices]\n",
    "        draw.rectangle(get_bounding_box(eyebrow_left_points), outline=(0, 255, 0), width=2)\n",
    "\n",
    "    if all(i < num_landmark for i in eyebrow_right_indices):\n",
    "        eyebrow_right_points = [landmarks[i] for i in eyebrow_right_indices]\n",
    "        draw.rectangle(get_bounding_box(eyebrow_right_points), outline=(0, 255, 0), width=2)\n",
    "\n",
    "    if all(i < num_landmark for i in eye_left_indices):\n",
    "        eye_left_points = [landmarks[i] for i in eye_left_indices]\n",
    "        draw.rectangle(get_bounding_box(eye_left_points), outline=(0, 255, 0), width=2)\n",
    "\n",
    "    if all(i < num_landmark for i in eye_right_indices):\n",
    "        eye_right_points = [landmarks[i] for i in eye_right_indices]\n",
    "        draw.rectangle(get_bounding_box(eye_right_points), outline=(0, 255, 0), width=2)\n",
    "\n",
    "    if all(i < num_landmark for i in nose_indices):\n",
    "        nose_points = [landmarks[i] for i in nose_indices]\n",
    "        draw.rectangle(get_bounding_box(nose_points), outline=(0, 255, 0), width=2)\n",
    "\n",
    "    if all(i < num_landmark for i in mouth_indices):\n",
    "        mouth_points = [landmarks[i] for i in mouth_indices]\n",
    "        draw.rectangle(get_bounding_box(mouth_points), outline=(0, 255, 0), width=2)\n",
    "\n",
    "# output image\n",
    "black_img.save('oujutput.bmp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "# from PIL import Image, ImageDraw\n",
    "# import torch\n",
    "# import torchvision.transforms as transforms\n",
    "\n",
    "# # Assuming CFA and other necessary imports are already available\n",
    "# # detector\n",
    "# face_detector = cv2.CascadeClassifier('lbpcascade_animeface.xml')\n",
    "# landmark_detector = CFA(output_channel_num=num_landmark + 1, checkpoint_name=checkpoint_name).cuda()\n",
    "\n",
    "# # transform\n",
    "# normalize = transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "# train_transform = [transforms.ToTensor(), normalize]\n",
    "# train_transform = transforms.Compose(train_transform)\n",
    "\n",
    "# # input image & detect face\n",
    "# img = cv2.imread(input_img_name)\n",
    "# faces = face_detector.detectMultiScale(img)\n",
    "\n",
    "# # Create a black image with the same size\n",
    "# black_img = np.zeros_like(img)\n",
    "# black_img = Image.fromarray(cv2.cvtColor(black_img, cv2.COLOR_BGR2RGB))\n",
    "# draw = ImageDraw.Draw(black_img)\n",
    "\n",
    "# # Convert the original image to PIL Image for cropping\n",
    "# img_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "# for x_, y_, w_, h_ in faces:\n",
    "\n",
    "#     # adjust face size\n",
    "#     x = max(x_ - w_ / 8, 0)\n",
    "#     rx = min(x_ + w_ * 9 / 8, black_img.width)\n",
    "#     y = max(y_ - h_ / 4, 0)\n",
    "#     by = y_ + h_\n",
    "#     w = rx - x\n",
    "#     h = by - y\n",
    "\n",
    "#     # draw result of face detection\n",
    "#     draw.rectangle((x, y, x + w, y + h), outline=(255, 255, 255), width=3)\n",
    "\n",
    "#     # transform image\n",
    "#     img_tmp = img_pil.crop((x, y, x+w, y+h))\n",
    "#     img_tmp = img_tmp.resize((img_width, img_width), Image.BICUBIC)\n",
    "#     img_tmp = train_transform(img_tmp)\n",
    "#     img_tmp = img_tmp.unsqueeze(0).cuda()\n",
    "\n",
    "#     # estimate heatmap\n",
    "#     heatmaps = landmark_detector(img_tmp)\n",
    "#     heatmaps = heatmaps[-1].cpu().detach().numpy()[0]\n",
    "\n",
    "#     # calculate landmark position\n",
    "#     for i in range(num_landmark):\n",
    "#         heatmaps_tmp = cv2.resize(heatmaps[i], (img_width, img_width), interpolation=cv2.INTER_CUBIC)\n",
    "#         landmark = np.unravel_index(np.argmax(heatmaps_tmp), heatmaps_tmp.shape)\n",
    "#         landmark_y = landmark[0] * h / img_width\n",
    "#         landmark_x = landmark[1] * w / img_width\n",
    "\n",
    "#         # draw landmarks\n",
    "#         draw.ellipse((x + landmark_x - 2, y + landmark_y - 2, x + landmark_x + 2, y + landmark_y + 2), fill=(255, 255, 255))\n",
    "\n",
    "#          # label landmarks\n",
    "#         draw.text((x + landmark_x + 5, y + landmark_y), str(i), fill=(255, 255, 255))\n",
    "\n",
    "\n",
    "# # output image\n",
    "# black_img.save('output.bmp')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
